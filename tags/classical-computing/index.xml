<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Classical Computing on Quantum Federated Learning Blog</title>
    <link>https://adbrei.github.io/qfl-research/tags/classical-computing/</link>
    <description>Recent content in Classical Computing on Quantum Federated Learning Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 03 Jun 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://adbrei.github.io/qfl-research/tags/classical-computing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Literature Review: &#39;&#39;How to get started in quantum computing&#39;&#39; </title>
      <link>https://adbrei.github.io/qfl-research/posts/post3/</link>
      <pubDate>Thu, 03 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://adbrei.github.io/qfl-research/posts/post3/</guid>
      <description>(Last updated: June 3, 2021)
Summary David Matthews&#39; paper &amp;ldquo;How to get started in quantum computing,&amp;rdquo; by Nature News, is an excellent survey paper of today&amp;rsquo;s state of computing. Published online just a few months ago on 4 March 2021, it summarizes fundamental ideas behind quantum computing motivating new research. The paper names leading companies and institutions who have been contributing to the swiftly growing field, and it distinguishes a few broad aspects of their approach.</description>
    </item>
    
    <item>
      <title>Classical versus Quantum Computing</title>
      <link>https://adbrei.github.io/qfl-research/posts/post2/</link>
      <pubDate>Wed, 02 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://adbrei.github.io/qfl-research/posts/post2/</guid>
      <description>(Last updated: June 3, 2021)
There exist a plethora of methods of computation. The most commonly used computation is classical computation. Here, we explore the basic differences between classical and quantum.
Classical Computing Also known as binary computing, classical computing is a system of computation that uses bits (represented by 0 and 1) to logically store and manipulate information. Historically, all computers from Babbage&amp;rsquo;s theoretical &amp;ldquo;analytical machine&amp;rdquo; to the supercomputers produced by Hewlett Packard Enterprise&amp;rsquo;s subsidiary, Cray Inc.</description>
    </item>
    
  </channel>
</rss>
